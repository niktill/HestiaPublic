{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsvaef1WAGRZ"
      },
      "source": [
        "## Training the AI Model\n",
        "\n",
        "This is the Jupyter Notebook to train the AI model. It is done via .ipynb, so Google Colab, especially their GPUs can be utilized. To do so click the following:\n",
        "\n",
        "Runtime --> Change runtime type --> *select GPU*\n",
        "\n",
        "Throughout the code, the developer can set different ways in how the AI model should be trained. For example, the models hyperparameters can be changed by declaring variabled or the developer can choose wether to tran a VGG model or a custom CNN by (un)commenting lines of code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37n2CuVoANyL"
      },
      "source": [
        "### Mount Drive and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21rUE1GundxS",
        "outputId": "cf17b24e-3881-4955-be87-fa91d0ed1e46"
      },
      "source": [
        "# For Execution in Google Colab\n",
        "# mount drive and set directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# navigate to your working FOLDER \n",
        "#FOLDER = '/content/drive/MyDrive/GDrive_Hestia/data/'\n",
        "#%cd $FOLDER\n",
        "\n",
        "PATH = '/content/drive/MyDrive/GDrive_Hestia/data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXu4KMv5AdRV"
      },
      "source": [
        "# For Execution in local Jupyter Notebook\n",
        "\n",
        "# PATH = \"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxPGyd5rnk0K"
      },
      "source": [
        "# CNN architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers.convolutional import *\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "# prediction\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# image pre-processing\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# visualization\n",
        "# from keras.callbacks import TensorBoard \n",
        "# from keras.callbacks import Callback # default callback -> test scores\n",
        "# from keras.callbacks import ModelCheckpoint # checkpointing model\n",
        "from keras.callbacks import *\n",
        "\n",
        "# optimizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# system and standard\n",
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image \n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemY8N5SsFV2"
      },
      "source": [
        "### Program parameter settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjkqri4Do9-9"
      },
      "source": [
        "# define data directories\n",
        "data_src = 'AIModel_data2' # directory with train, dev, test set\n",
        "train_data_dir = f'{PATH}{data_src}/train' # contains two classes: no_tackle and tackle - one subdirectory per class\n",
        "dev_data_dir = f'{PATH}{data_src}/dev'\n",
        "test_data_dir = f'{PATH}{data_src}/test'\n",
        "\n",
        "# define name of nb aka name of classifier model\n",
        "nbname = 'CNN_ep5'\n",
        "\n",
        "# define batch sizes\n",
        "train_batch_size = 50 # 50  \n",
        "dev_batch_size = 17 # 17 \n",
        "test_batch_size = 15 # 15 \n",
        "\n",
        "# define image size, ideally what its actual site is\n",
        "# for other CNN architectures (i.e. Transfer Learning) this can deviate\n",
        "img_width, img_height = 1152, 648\n",
        "# VGG 16 input shapes\n",
        "#img_width, img_height = 244, 244\n",
        "\n",
        "# define number of training epochs\n",
        "nb_epoch = 5\n",
        "\n",
        "# define model parameters\n",
        "learning_rate = 0.001  # other optimizer param are set to default\n",
        "\n",
        "# define callbacks\n",
        "#tensorboard = TensorBoard(log_dir=f'TB_logs/{nbname}')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTnxnQACsADt"
      },
      "source": [
        "### Data input and data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVwbpal7rv61",
        "outputId": "8efe7fd3-298a-41fa-ab62-a714dfaeebed"
      },
      "source": [
        "# define datagenerators\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "        \n",
        "dev_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "# flow from direcory: Takes the path to a directory & generates batches of augmented data.\n",
        "# train-batches\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_data_dir,\n",
        "    target_size=(img_width, img_height),  # the dimensions to which all images found will be resized\n",
        "    color_mode='rgb',\n",
        "    classes=['no_tackle', 'tackle'],  # per default alphanumeric order; here specified for dynamic reasons\n",
        "    class_mode='binary',  # 1D binary labels: 1.0 and 0.0 needed for binary_crossentropy loss; \"categorical\" will be 2D one-hot encoded labels: [1. 0.] [0. 1.]\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True, \n",
        ")\n",
        "\n",
        "# valid-batches\n",
        "dev_generator = dev_datagen.flow_from_directory(\n",
        "    directory=dev_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode='rgb',\n",
        "    classes=['no_tackle', 'tackle'],\n",
        "    class_mode='binary',\n",
        "    batch_size=dev_batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# test-batches\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode='rgb',\n",
        "    classes=['no_tackle', 'tackle'],\n",
        "    class_mode='binary',\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 68 images belonging to 2 classes.\n",
            "Found 62 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vAYH5Tusjvv"
      },
      "source": [
        "### CNN model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTRsIDm4YWMh"
      },
      "source": [
        "##### Sequential model: standard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5V3uioNsftH"
      },
      "source": [
        "# keras sequential model\n",
        "model = Sequential([\n",
        "    Conv2D(filters=16, kernel_size = (7, 7), strides=(1, 1), padding='same', input_shape=(img_width, img_height, 3)),  # RBG images\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=16, kernel_size = (7, 7), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(6, 6), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Conv2D(filters=16, kernel_size = (7, 7), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=16, kernel_size = (7, 7), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(6, 6), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Conv2D(filters=32, kernel_size = (5, 5), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=32, kernel_size = (5, 5), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(4, 4), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Conv2D(filters=32, kernel_size = (5, 5), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=32, kernel_size = (5, 5), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(4, 4), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Conv2D(filters=64, kernel_size = (3, 3), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=64, kernel_size = (3, 3), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Conv2D(filters=64, kernel_size = (3, 3), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters=64, kernel_size = (3, 3), strides=(1, 1), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(units=64),\n",
        "    Activation('relu'),\n",
        "    \n",
        "    Dropout(rate=0.5),\n",
        "    \n",
        "    Dense(units=1),\n",
        "    \n",
        "    Activation('sigmoid')  # binary clasification\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmJbmdrPYcOI"
      },
      "source": [
        "##### VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0-Wl14yYQNt"
      },
      "source": [
        "# keras sequential model: VGG 16.\n",
        "\n",
        "# create the base model\n",
        "base_model = VGG16(include_top=False,\n",
        "                   weights='imagenet',\n",
        "                   input_shape=(img_width, img_height, 3)\n",
        "                  )\n",
        "\n",
        "x = base_model.output # output of original VGG16 model without top\n",
        "\n",
        "# add FC layers\n",
        "x = Flatten(input_shape=(None, None, 512))(x) # takes output of base_model and flattens it to 1D tensor\n",
        "x = Dense(units=128, activation='relu')(x)\n",
        "x = Dense(units=64, activation='relu')(x)\n",
        "\n",
        "x = Dropout(0.5)(x) # Dropout of 0.5 is applied to original VGG16 architecture\n",
        "\n",
        "predictions = Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "# final model instance used for training, combine base_model and newly subsituted top layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# set how much of the network should be retrained\n",
        "changing_point = 11 # values: 4, 7, 11, 15, 19 and 0; exact layer can be entered as Keras starts with layer 0\n",
        "for layer in model.layers[:changing_point]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[changing_point:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix7n3rpathl8"
      },
      "source": [
        "# compilation: configuration of learning process\n",
        "model.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),  # best practice hparam from authors of ADAM paper\n",
        "              loss='binary_crossentropy',  # most useful loss for binary classification\n",
        "              metrics=['accuracy']  # judge perfomance of model, results not used for training of model\n",
        "             ) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCzxRkHmuCL2"
      },
      "source": [
        "### Train AI Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQcNN-KV8zh0"
      },
      "source": [
        "# to use if keras model should not save; comment in respective callbacks in model.fit\n",
        "# source: https://stackoverflow.com/questions/63074971/keras-model-save-isnt-saving\n",
        "\n",
        "# filepath= \"/content/drive/MyDrive/GDrive_Hestia/data/models/epochs:{epoch:03d}-val_acc:{val_accuracy}.hdf5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "# callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiExC0SHDCO-",
        "outputId": "28d4f623-43e9-42e8-cdd8-373287c90dbf"
      },
      "source": [
        "start = datetime.now()  # get current time\n",
        "\n",
        "# fits the model on data generated batch by batch by ImageDataGenerator\n",
        "model.fit(train_generator, # train data\n",
        "                    steps_per_epoch=len(train_generator), # (number of images / batch-size) = len(train_generator) \n",
        "                    epochs=nb_epoch, # epoch is iteration over entire data provided\n",
        "                    verbose=1, # how much output seen on console: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "                    #callbacks = [tensorboard], # callbacks return information from a training algorithm while training is taking place\n",
        "                    validation_data=dev_generator, # evaluate loss and other model metrics at the end of each epoch\n",
        "                    validation_steps=len(dev_generator) # (number of images / batch-size) = len(dev_generator)\n",
        "                    #callbacks=callbacks_list\n",
        "                    #validation_freq = None\n",
        "                   )\n",
        "\n",
        "end = datetime.now() \n",
        " \n",
        "print(f\"Training execution time: {(end-start).seconds},{int((end-start).microseconds/100)} seconds\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "8/8 [==============================] - 156s 12s/step - loss: 0.6951 - accuracy: 0.4175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 25s 3s/step - loss: 0.6928 - accuracy: 0.5142 - val_loss: 0.6822 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 24s 3s/step - loss: 0.6277 - accuracy: 0.5571 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 24s 3s/step - loss: 0.2516 - accuracy: 0.9238 - val_loss: 0.3128 - val_accuracy: 0.9265\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 24s 3s/step - loss: 0.2679 - accuracy: 0.9255 - val_loss: 0.0539 - val_accuracy: 0.9853\n",
            "Training execution time: 264,6110 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go5oUrmCuKZR"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB9KZSTxuM63",
        "outputId": "f403f23c-e5c0-47c4-b856-ff04959cd623"
      },
      "source": [
        "# evaluate on test set\n",
        "testeval = model.evaluate(test_generator, # test data\n",
        "                          steps = len(test_generator)\n",
        "                                )\n",
        "print (f\"\\nTest Loss: {testeval[0]}\")\n",
        "print (f\"Test Accuracy: {testeval[1]}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 12s 2s/step - loss: 0.0274 - accuracy: 1.0000\n",
            "\n",
            "Test Loss: 0.0273622814565897\n",
            "Test Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM6xDtz7DiPB",
        "outputId": "eb250dbf-72b5-46f0-e639-86604b2e8f4f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1152, 648, 16)     2368      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1152, 648, 16)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1152, 648, 16)     12560     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1152, 648, 16)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 576, 324, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 576, 324, 16)      12560     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 576, 324, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 576, 324, 16)      12560     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 576, 324, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 288, 162, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 288, 162, 32)      12832     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 288, 162, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 288, 162, 32)      25632     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 288, 162, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 144, 81, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 144, 81, 32)       25632     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 144, 81, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 144, 81, 32)       25632     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 144, 81, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 72, 41, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 72, 41, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 72, 41, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 72, 41, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 72, 41, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 36, 21, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 36, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 36, 21, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 36, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 18, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12672)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                811072    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,070,193\n",
            "Trainable params: 1,070,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8E0B1WPSGs2"
      },
      "source": [
        "### Export Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-yIM4IS9pfW"
      },
      "source": [
        "# change dir path to save model\n",
        "os.chdir(PATH)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPxal6rdYuWF",
        "outputId": "a875291f-2583-432f-c24a-409c3e13fc35"
      },
      "source": [
        "# save model: comment in / out which saved model version you need for your OS\n",
        "\n",
        "# needs a read-only disable for savedfolder which under windows 10 on some version numbers is not posssible to achieve  \n",
        "model.save(f'models/{nbname}_1')\n",
        "\n",
        "# .h5 is depracted\n",
        "model.save(f'models/{nbname}_1.h5')\n",
        "\n",
        "#model.save(f'/models/{nbname}.tf') "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/CNN_ep5_1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI9L61pUXdiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}